---
{"dg-publish":true,"permalink":"/Instant_notes/Notes/Int.1405_版本3/"}
---

# 2025-08-17 14:05
> What's on your mind?
# Version 3
为了解决[[Instant_notes/Notes/Int.1438_版本2\|Int.1438_版本2]]中的定位问题，我需要探讨一下问题：
在我的应用中实现高精度的文本定位，火山引擎官方推荐的最佳实践是什么？是依赖于强大的Prompt Engineering，还是有其他API特性或工具可以利用？我决定先仔细查看火山方舟的[官方文档](https://www.volcengine.com/docs/82379)。
豆包官方提供了一个AI对话窗口，可以通过与其对话来获得和产品文档相关的全部信息，可以跟它对话，询问响应的问题，并得到对应的答案，然后向工程师提供正确的相关信息，以便实现相关功能。

火山方舟推荐实现高精度文本定位的最佳实践是：
>结合 Prompt Engineering与结构化输出工具：精准提示设计：明确任务目标（如“提取文档中所有病症”），使用分隔符区分输入（如```包裹文本），并限制输出格式（如{"disease": ["病症1", "病症2"]}），可以参考[Prompt 最佳实践](https://www.volcengine.com/docs/82379/1221660)。
结构化输出 API：通过指定 response_format 参数强制模型返回 JSON 等格式，减少解析误差。此处可以参考[结构化输出](https://www.volcengine.com/docs/82379/1568221)。

## 快速校对功能
我认为针对我version 3的高亮问题，可以提这些有效地问题：
```
1.“为了实现‘快速校对’功能，我需要豆包模型非常可靠地返回一个包含错误列表的JSON数组。我应该如何设计我的Prompt，才能最大程度地保证模型始终返回结构正确的JSON，而不是普通的对话文本？”
2.“我计划在Prompt中提供一个清晰的JSON结构示例，并用指令强调‘必须且只能返回JSON’。这种方法在豆包模型上足够稳定吗？是否有更可靠的技术，比如类似OpenAI的'Function Calling'功能，可以强制模型输出合规的结构化数据？”
3.“对于强制输出JSON这种结构化任务，‘doubao-seed1.6 flash’和‘doubao-seed 1.6’的遵循指令能力（Instruction Following）有多大差异？轻量版模型是否能够稳定地完成这个任务？”
```
关于这些问题的回复，请参考[[Int.1612_快速校对问题]]，当然，还有很多细节需要在响应的产品文档里去看，以打磨出最好的产品。

## Background dimming定位功能
针对version3的background dimming定位不准确的问题,可以提以下问题：
```
1. “在我的对话功能中，我希望模型在引用原文时，能用自定义的XML标签（如 `<focus>原文在这里</focus>`）将引用的部分包裹起来。我应该如何在Prompt中描述这个规则，才能让模型最稳定地遵循它？”
2. “除了在Prompt中明确说明规则，是否有其他技巧（比如使用示例、Few-shot learning）可以提高模型遵循这种特殊文本标记格式的稳定性？对于豆包模型来说，哪种技巧最有效？”
3.“为了让模型的输出更具确定性、更少地自由发挥，以便更好地遵循我的格式化指令，我是否应该调整API中的某些参数，比如将 `temperature` 设置为0或一个很低的值？这会对分析质量产生负面影响吗？”
```

关于这些问题的回复，我在[[Int.1615_背景聚焦问题]]中，进行进一步的讨论。
当然，还可以问综合性更加强的问题：
```
 “综合来看，为了在我的应用中实现高精度的文本定位，火山引擎官方推荐的最佳实践是什么？是依赖于强大的Prompt Engineering，还是有其他API特性或工具可以利用？”
```

# 我的快速原型策略
我准备给搞两个AI，一个作为产品经理负责理解豆包的官方文档和我的需求，一个做程序员，解决技术问题，优化技术方案。三方协同工作以实现最好的产品效果。
## 产品经理prompt 提示词策略
你作为一个产品经理，需要根据现在产品存在的技术痛点，负责向豆包的官方文档助手提出相应的问题，然后由我来与其沟通，获取响应的回复，然后经由我把回复交给你。你再向工程师提出需求，你能理解吗？
## 程序员提示词策略
一个负责构建代码和debug
关于快速校对的回答